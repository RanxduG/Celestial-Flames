{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RanxduG/Celestial-Flames/blob/main/Question1answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "SVWJCKARx3_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# models.py\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn_utils"
      ],
      "metadata": {
        "id": "2B71rXzfxwK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODELS FOR PART 1"
      ],
      "metadata": {
        "id": "Zyz28Y_gx_Ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConsonantVowelClassifier(object):\n",
        "    def predict(self, context):\n",
        "        raise Exception(\"Only implemented in subclasses\")"
      ],
      "metadata": {
        "id": "32VcLRY-xyvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FrequencyBasedClassifier(ConsonantVowelClassifier):\n",
        "    def __init__(self, consonant_counts, vowel_counts):\n",
        "      self.consonant_counts = consonant_counts\n",
        "      self.vowel_counts = vowel_counts\n",
        "\n",
        "\n",
        "    def predict(self, context):\n",
        "      if self.consonant_counts[context[-1]] > self.vowel_counts[context[-1]]:\n",
        "          return 0\n",
        "      else:\n",
        "          return 1"
      ],
      "metadata": {
        "id": "uG6nk0KZx1bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 2)  # *2 due to bidirectional LSTM\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = self.dropout(lstm_out[:, -1, :])  # Apply dropout to the last LSTM output\n",
        "        final_output = self.fc(lstm_out)\n",
        "        return final_output\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.eval()  # Set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            outputs = self.forward(x)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "        return predicted\n"
      ],
      "metadata": {
        "id": "ZQvRKjhDyTH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_frequency_based_classifier(cons_exs, vowel_exs):\n",
        "    consonant_counts = collections.Counter()\n",
        "    vowel_counts = collections.Counter()\n",
        "    for ex in cons_exs:\n",
        "        consonant_counts[ex[-1]] += 1\n",
        "    for ex in vowel_exs:\n",
        "        vowel_counts[ex[-1]] += 1\n",
        "    return FrequencyBasedClassifier(consonant_counts, vowel_counts)"
      ],
      "metadata": {
        "id": "-yYUhKKgyZul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_rnn_classifier(args, train_cons_exs, train_vowel_exs, dev_cons_exs, dev_vowel_exs, vocab_index):\n",
        "    # Updated hyperparameters\n",
        "    embedding_dim = 50 #dont change this\n",
        "    hidden_dim = 128 #execution time increases if this increases\n",
        "    vocab_size = len(vocab_index)\n",
        "    dropout_rate = 0.7 #dont increase this\n",
        "    batch_size = 128 #execution time increases if this increases\n",
        "    num_epochs = 50 #dont change this\n",
        "\n",
        "    # Initialize the model\n",
        "    model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, dropout_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "    # Prepare training data\n",
        "    train_data = train_cons_exs + train_vowel_exs\n",
        "    labels = [0] * len(train_cons_exs) + [1] * len(train_vowel_exs)\n",
        "\n",
        "    # Convert examples to indices\n",
        "    train_indices = [[vocab_index[c] for c in ex] for ex in train_data]\n",
        "\n",
        "    # Pad sequences to the same length\n",
        "    train_indices_tensor = rnn_utils.pad_sequence(\n",
        "        [torch.tensor(seq, dtype=torch.long) for seq in train_indices],\n",
        "        batch_first=True\n",
        "    )  # [batch_size, max_seq_length]\n",
        "\n",
        "    train_labels_tensor = torch.tensor(labels, dtype=torch.long)  # [batch_size]\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for i in range(0, len(train_indices_tensor), batch_size):\n",
        "            batch_x = train_indices_tensor[i:i + batch_size]\n",
        "            batch_y = train_labels_tensor[i:i + batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_x)\n",
        "            loss = criterion(output, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluation on development set\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        dev_data = dev_cons_exs + dev_vowel_exs\n",
        "        dev_labels = [0] * len(dev_cons_exs) + [1] * len(dev_vowel_exs)\n",
        "\n",
        "        # Convert development examples to indices\n",
        "        dev_indices = [[vocab_index[c] for c in ex] for ex in dev_data]\n",
        "\n",
        "        # Pad development sequences to the same length\n",
        "        dev_indices_tensor = rnn_utils.pad_sequence(\n",
        "            [torch.tensor(seq, dtype=torch.long) for seq in dev_indices],\n",
        "            batch_first=True\n",
        "        )  # [batch_size, max_seq_length]\n",
        "\n",
        "        # Get predictions\n",
        "        predicted_labels = model.predict(dev_indices_tensor)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct_predictions += (predicted_labels == torch.tensor(dev_labels)).sum().item()\n",
        "        total_predictions += len(dev_labels)\n",
        "\n",
        "        # Print results\n",
        "        for i, prediction in enumerate(predicted_labels):\n",
        "            actual = dev_labels[i]\n",
        "            result = \"Correct\" if prediction.item() == actual else \"Incorrect\"\n",
        "            print(f'Example: {dev_data[i]}, Predicted: {prediction.item()}, Actual: {actual}, Result: {result}')\n",
        "\n",
        "    # Accuracy calculation\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(f'Accuracy on Development Set: {accuracy:.4f}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "d1FigPEMyXgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DATA LOADING AND TRAINING"
      ],
      "metadata": {
        "id": "iPGYwPfBybno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-3lVgj3TpeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63a4d406-a4e7-4a77-f174-a61b66378119",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 98.8607\n",
            "Epoch 2/50, Loss: 107.0596\n",
            "Epoch 3/50, Loss: 64.1336\n",
            "Epoch 4/50, Loss: 51.5022\n",
            "Epoch 5/50, Loss: 49.4648\n",
            "Epoch 6/50, Loss: 49.5472\n",
            "Epoch 7/50, Loss: 48.9637\n",
            "Epoch 8/50, Loss: 48.9198\n",
            "Epoch 9/50, Loss: 48.7752\n",
            "Epoch 10/50, Loss: 48.4145\n",
            "Epoch 11/50, Loss: 48.1088\n",
            "Epoch 12/50, Loss: 47.8295\n",
            "Epoch 13/50, Loss: 47.3403\n",
            "Epoch 14/50, Loss: 46.8559\n",
            "Epoch 15/50, Loss: 46.4586\n",
            "Epoch 16/50, Loss: 45.7394\n",
            "Epoch 17/50, Loss: 45.1634\n",
            "Epoch 18/50, Loss: 44.4679\n",
            "Epoch 19/50, Loss: 44.0345\n",
            "Epoch 20/50, Loss: 43.1315\n",
            "Epoch 21/50, Loss: 42.4870\n",
            "Epoch 22/50, Loss: 43.0631\n",
            "Epoch 23/50, Loss: 41.9525\n",
            "Epoch 24/50, Loss: 41.2354\n",
            "Epoch 25/50, Loss: 41.2580\n",
            "Epoch 26/50, Loss: 40.6848\n",
            "Epoch 27/50, Loss: 39.9812\n",
            "Epoch 28/50, Loss: 38.9078\n",
            "Epoch 29/50, Loss: 38.4998\n",
            "Epoch 30/50, Loss: 37.9506\n",
            "Epoch 31/50, Loss: 37.4029\n",
            "Epoch 32/50, Loss: 36.8168\n",
            "Epoch 33/50, Loss: 36.2430\n",
            "Epoch 34/50, Loss: 35.5242\n",
            "Epoch 35/50, Loss: 34.8855\n",
            "Epoch 36/50, Loss: 34.4566\n",
            "Epoch 37/50, Loss: 33.3000\n",
            "Epoch 38/50, Loss: 33.0098\n",
            "Epoch 39/50, Loss: 32.5402\n",
            "Epoch 40/50, Loss: 31.8783\n",
            "Epoch 41/50, Loss: 31.6122\n",
            "Epoch 42/50, Loss: 30.1516\n",
            "Epoch 43/50, Loss: 30.6025\n",
            "Epoch 44/50, Loss: 29.3584\n",
            "Epoch 45/50, Loss: 29.4187\n",
            "Epoch 46/50, Loss: 28.8092\n",
            "Epoch 47/50, Loss: 27.7451\n",
            "Epoch 48/50, Loss: 27.1477\n",
            "Epoch 49/50, Loss: 27.0087\n",
            "Epoch 50/50, Loss: 26.8680\n",
            "Example: g certain people whi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: companied by an atte, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: from italian fascis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: one of these toys t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: to ideological anar, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: re characterized by, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: nd holds that govern, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ed by rank and file, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tropical regions e, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e cdd from rett synd, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: the franco regime w, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: rs existed with the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: using labor notes w, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: coercive economic in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: litical parliamentar, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: her needs to become, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: and robert a heinlei, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: cnt supporters led, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: tainability eco anar, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: or is displaying thi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: mmunicate at least i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: r a post revolutiona, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ruler of abu dhabi a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: most easily encounte, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ife resources and in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: cate have explained, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: mple is daniel tamme, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: er anarchism such ac, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: is is perhaps the pa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: with violence and de, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: mpatible with those, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: the cgt moved away, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ing fascists with ph, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: eminism which sees t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: child will deteriora, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ifism opposition to, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ments in argentina i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: six see anarchism i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ormal anarchist labo, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: erns of interests an, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: anarchism for examp, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: a manner consistent, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: work described commu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: seek a cure for auti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ist reader has helpe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: angle of incidence o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: that before recorde, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ection of any idea t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: r but not necessaril, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: l than competition i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: dscape over antarcti, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: nland oases of al ai, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: inancial wealth inve, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s open source progra, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: vocal variations ho, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: t with anarchist pri, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: dhabi chamber of co, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: franco regime which, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: when an environmenta, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: agnoses of high func, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: a philosophy anarchi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: alists believed in a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ero zero of the diag, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: nearby forested area, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: olicy and anarchist, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: autistic students ha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: into space neunke a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: well secure its las, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: racterization utopia, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rial workers of the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rease would focus mo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: stamps in one nine, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: l tones or phraseolo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: n the subject was pu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: t autism results fro, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: intellectual interes, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ve different albedo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: chedules or lighthou, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: illes deleuze and f, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ticle anarchism ideo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ge may not tend towa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: arrying out acts of, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: n activity in which, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: people e g by a lac, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ism is not a single, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: was joseph d jacque, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e or body it is the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e links to active wo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ith post left anarch, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: nce to jesus teachin, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: dequate speech marke, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: out autism and possi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ped in the context o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to one five zero ze, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nsively covered on t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: autistic person is i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: sical occupational a, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: al and have good mus, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: bakunin when he refu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: and facial expressio, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: gration dysfunction, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: th only a slight inc, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ism and society civi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: there are more very, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: wer and then begin i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: one on one lesson s, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: n of documentaries i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: l institutes of heal, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: the major city of ba, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: fferent form of auti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: m everything you nee, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nd abu dhabi branche, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tology climate forci, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: achings and utterly, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: manual s diagnostic, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: nine one eight kron, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t history with scien, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: d as an autistic spe, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t match those used b, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ption that asperger, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ith autism do not ma, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: autism and autistic, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: cial communication o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: time repeatedly flap, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: sm and asperger s sy, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nt to the topic of a, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: on a t shaped islan, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ted arab emirates af, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: cided that sheikh za, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ction usually expres, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ht be re used agains, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rom black carbon par, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: information technolo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s can also extend in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: against a common fa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: y of value proudhon, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: are capable of emplo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: uses on publicly con, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ion to anybody who i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e united states the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: thout autism often i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: olsheviks in both fe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ain manifestations o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rder to be cured the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: in the one nine one, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: belief in non violen, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: standing autistic bo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ng a proper assessme, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: erse with other auti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ereignty black anarc, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ions hundreds of ana, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ell field system neo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ups in germany and t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s perspective a beha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e three rd millenniu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rchists male or fema, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rise by doing so the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ornia one seven octo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: reflecting their fee, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: lization in this cri, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: t against in one eig, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: re integrated into t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: routines or rituals, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: the overwhelming di, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: wo zero th century t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: oman and qatar the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: p however the bolshe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nual of mental disor, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ne one zero october, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: awareness a tendenc, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ci n general del tra, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: lection in reflectin, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: aders would end up a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: oy has popularized a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: o simple compatibili, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: was underway in repo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ent others particula, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: seven zero s during, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: m takes different pa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: komboa ervin and sa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ement the russian re, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ult choices should t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: one nine one two nu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: onversation is hard, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: n communists was sup, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: interpretations base, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: literature this dis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: c files open source, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hists the word anarc, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: zero a barren field, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: any autistic people, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rent and teachers ha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ring the albedo and, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: s about seven with o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: include ashanti als, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ht nine five anarchi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: iation dense swampla, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: the cnt played a ma, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: stent preoccupation, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: here was no clear in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ip of six zero zero, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rmy led by nestor ma, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hone syndicalists cn, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: dresses feminist con, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: utism autism present, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: uditory system of a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ancient china kropot, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: e to life in abu dha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: dhon it is commonly, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: n violence and uses, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: r until the middle o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: are on a continuum k, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: iving force behind t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: pervasive developmen, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: re effect is most fa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ocolonialism and glo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: d the temperature te, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ern anarchism for co, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: during childhood sin, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tends to increase t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: unal goods and wealt, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: vism french style sy, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ould in the spanish, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ials warmer regions, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ling class they had, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: already have one au, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to inspire some con, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: into other people s, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: tminster culture wit, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: situations by writi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: unlike other branche, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: most of western euro, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: dicated to explainin, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: litarianism used by, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: f brain injured chil, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: culottes of the fren, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rchist they organize, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: just another form o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: autistic spectrum o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: can indian movement, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: has begun to develo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e were transformed b, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: stop soon afterward, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: her hands some of t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: information service, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: xpression body postu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ded with an attempte, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: speak often use lan, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t milieu it often fo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: cnt played a major, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: e cgt and iww began, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: that can provide sup, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to known as the orga, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: o be treated as a mi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: al workers of the wo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: he also criticizes t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: erson with autism al, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ber revolution and t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: world bank world tra, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: often been associate, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to autism treatment, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: force rather than re, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t exclusively female, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: sis on support and a, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: and babble during t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: d with lfa is not ri, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: esources com offerin, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: covered zones winte, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nctioning labels in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: so disagreement abou, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to being able to fin, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ts participated alon, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: n language and typin, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: age industrial worke, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: f she has been talki, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: latives of family me, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: hs of life but stop, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: i as pearls represen, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: mmon misperception t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: inters of the mind i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ll because they stil, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: eate the structures, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: color of the sand re, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ack interest in othe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: to find occupations, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: capitalism mutualis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rchism for continuin, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s even when they see, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: a certain area of s, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: rofessors in the cur, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: istic people to lear, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: are controversial an, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: difficulties by age, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: d the label early in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ll forms of hierarch, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: tion altogether late, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: n for autism autism, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t the business of a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: that if a marxist pa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: environment and equa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ists and other left, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: same phrase over an, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ve feminist mary wol, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: carelessness poor bo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ter would help out a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: asts by allowing the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ee generally al fahi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: al to the general pu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: he two zero th centu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ystematic teaching a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: it unity action sel, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: chism at all is high, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ely is only about ni, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: oilt middle class di, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ot rising quite as s, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ng and the free soft, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: n that a letter had, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: rucial states postma, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: one w m two in the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e side abu dhabi ara, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: uction of dates and, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: tition would elimina, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: p as a positive labe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rger s syndrome and, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ey trust human right, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ion there are severa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: d after prospecting, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: as a primary strate, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: impairs them even i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: t with every one of, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ndicalism was an ear, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: different technique, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tuationism post colo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: capitalist bryan cap, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: x seven now part of, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: eedom tucker strongl, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: y believe treatment, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: onality types the sa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rests much effort ha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: idualist feminist we, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: autism spectrum quo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: of eight and the wor, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ing stirner never ca, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tself from the tradi, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: even before the eve, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ave trouble hearing, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ther than speaking i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s current ruler his, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ainst capitalism wit, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: a was created in dow, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: on to mean the world, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: deed johann most wa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: system development o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: st birthday a typica, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e twentieth century, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e the reality of bol, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ical philosophy is t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: eriodical ever publi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ssues continued unti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: mexico is a cultura, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: g called collectivis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: was created as a fo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: sics view of abu dha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s can use to assist, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: em communication dif, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: consequences of mar, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: e elite interests mu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ructures which absor, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: any and the uprising, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: oercion making the p, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: at every moment by t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: wever in practice ma, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: eek one of the inspi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: lack anarchism natio, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: used in two differen, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: en inappropriately a, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ersonal backing of b, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rent meanings to dif, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: sts however dismiss, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ader has helped to s, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ro to a maximum in t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: manev h aminoglycosi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: previously normal be, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: growth of the cultu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: one or more stereoty, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: increases in autism, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: be differentiated f, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: p soon afterwards ot, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: pitched sing song o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: five f year round w, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ontroversial this ar, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: narchist movement ye, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ight it is widely co, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: olished although the, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ame from the mutuali, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ith personality type, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: d wave feminist move, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: orld war ii in germa, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ional workingmen s a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: deas were influentia, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: l depend on the colo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: itain in one eight t, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ynthesis of anarchis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: oduction began on da, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: igious traditions wi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: u vote and they deci, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: tablished churches t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: early infantile auti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: onent of nonviolent, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: r indication that a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: pectrum disorder ano, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: about the appropria, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nt of working time i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: urs lining up their, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: in particular have, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: falls there it is a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ger s syndrome autis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: he united arab emira, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: consistent with libe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hing other than chao, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: change due to an in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: habi com abu dhabi c, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ure as a metaphor fo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: story abu dhabi the, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: not use the word ana, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: utopianism anarchis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: orld the autistic co, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: italism anarchism an, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: but lies well offsho, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: have imaginary frien, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rchism anarchism in, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: onmental triggers an, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: internationally man, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: s and kanner s synd, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: variant normal beha, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: trees as readily stu, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: our autism spectrum, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: reflected human acti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: parent rise is proba, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hist society many po, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: he origin of the con, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: by at least two of, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: rom a higher concent, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: viduals with autism, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: one eight th centur, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: lished anarchists ar, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: vary the most from, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: t seems to non autis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: k hakim bey and othe, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ators the zapatista, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: eated as a minority, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: rchism at all is hig, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: asperger described, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: xample communist par, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ny as one united sta, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: is us published jour, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: still think of auti, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: he area appears to i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: thout repressive for, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: syndicalism murray, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ometimes in strong o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: omy of abu dhabi con, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: a final split betwee, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hip is as important, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: y need there are man, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ned and a gift cultu, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ate the issue in sea, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rchists oppose neoco, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: l formet in the one, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: varies depending on, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: d schools have appea, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: heoretical unity tac, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: fication of the theo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: e popular theories i, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ional left communist, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: hree rd millennium b, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: istic people the ter, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: conversations the gi, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ree days showed a lo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: l functioning have a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: hat the personal pre, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: n such as tree sitti, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: ces william godwin a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ible or plain utopia, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rt services to achie, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: fects in education c, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: velopmental disorder, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: lds that the belief, Predicted: 1, Actual: 0, Result: Incorrect\n",
            "Example: abu dhabi time out a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ne trees and therefo, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: s movements and his, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: rees tend to have a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: are generally hot a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: serious damage to a, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: epends on the size o, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: nsion of the divisio, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: syndicalism after t, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: ortrayed as dangerou, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: in american anarchis, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: information we recei, Predicted: 0, Actual: 0, Result: Correct\n",
            "Example: spectrum disorder c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: surface completely, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: he dsm iv criteria f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: seeks to gain and c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: teacher may be tell, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: er in practice many, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: o three one zero zer, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: elopmental disabilit, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ctivity to touch mov, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ange the difference, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: abu dhabi soon acqu, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lar front electoral, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: equal access to res, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lity and justice pro, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: one of the other fo, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: continued to flow t, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: how well we integrat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ources com offering, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ity to see things fr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: narcho syndicalist m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: and folk music are, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s for recovery from, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tistics find it easi, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: terpretations based, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: behaviour but does n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: capped to those whos, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: n including the das, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: te and form online c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: benjamin tucker in, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: zick and robert a he, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ic conversation is h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ation skills social, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: by an average of abo, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: us musical styles an, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: autistic spectrum t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tions that manifest, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: graph from the nati, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: system development, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: a greater risk of he, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: us on autism selecti, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: the spectrum of vis, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: principle of author, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: te power both domest, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ds don t let the pol, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: vided with some memb, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: the mexican revolut, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: competition in one f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ociation between sav, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: reactions dsm defin, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: cal autism regressiv, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s the first major an, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ultimately just a th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: syndicalism continu, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: sition to war to be, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: tism spectrum disord, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: characteristics dr l, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ture which has evolv, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: utistic body languag, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rth is about three z, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: um quotient aspie qu, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ned that companionsh, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: to the student the a, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: cant movement in eur, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eikh zayed became th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eople with autism us, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ovement in spain unt, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: en one and the feder, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lated many are activ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: new harmony which f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: fertilization on th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ne seven subsequent, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: on as manifested by, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ntion for autism aut, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: r importance is the, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: by means of rifles b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: archo primitivists s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lthough people with, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f the following mark, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nist i am an individ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t necessarily true c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: viduals would unite, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: widely considered t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: onetheless key think, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: vague and subjectiv, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ft section on anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: opposes the existenc, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: democrats etc and t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t major anarcho synd, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: on one lesson struct, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ed arab emirates aft, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ding rival internati, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: narcho syndicalists, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ing encompassing pre, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ilar philosophies ex, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: paper wasn t transl, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: m generally prefer c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ployment crisis in m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ance that has inspir, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f a student s disord, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ely geeks with a med, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: onversations the giv, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anglophone and europ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: d neurological evalu, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: al of six or more it, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: label attached also, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: t is not clear wheth, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rs lining up their c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ans of regulating vi, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: parent or more subtl, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tanding people s tho, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: drop to a value of, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: which represented th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ce and destruction s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hist trade union fed, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: must be built with d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: xample benjamin tuck, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ture not just autist, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: toward voices grasp, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: these stances are l, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: is sensory integrati, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: sts argue that the r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: and slavery the tre, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: hese individuals to, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: and uses violence t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: roups essentially th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: vement these cyber c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: other hand hand fred, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: subject of the docum, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: graph courtesy joshu, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: they may react negat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eople many people us, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f abu dhabi al ain m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ne eight four eight, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: p free women organiz, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: blicity surrounding, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: tion created by the, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: dia infoshop org wik, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: er and alfredo m bon, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ersies in autism eth, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: kronstadt rebellion, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eight one nine one z, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ith banks boutiques, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ime between six and, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: they do not believe, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: and restricted repet, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: child s daily routin, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: individualist anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tism is present at b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: o give more elaborat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: edition text revisi, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: w of equal freedom t, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: s sometimes seen in, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: d juliette adam crit, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: c and its early hist, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: onal became signfici, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: cal ever published b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: he rise of an import, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ark tropical rainfor, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: leo kanner of the j, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: with working in gro, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: archy russell means, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: parliamentarianism, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e felt co operation, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: heikdoms which made, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: high pitched sing s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e fact that many aut, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: whilst professing r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: m liberty xiv decemb, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anti cure movement s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: an individual with, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: feedback if a snow c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rder communication d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: c adults engage in m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ng the diggers of th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: libertarian histori, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: riticizes anarchism, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lobal warming the cl, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e religious forerunn, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: anish cnt as its man, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: be a truly free soci, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ial and some clinici, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: i racist action is n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tual property is und, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ection of research s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: arms or wiggling th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: lar importance is th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e zero zero four zer, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: n just as neurotypic, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: acts of individual t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t part of the autist, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: uch as sir herbert r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: erences involved in, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: heir average albedo, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: te speech marked imp, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rcho syndicalism adv, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e student to know wh, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: oken advocates of th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: al western coast an, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: oment the social dem, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ther autistics due t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ds or throughout the, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: one zero zero zero z, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: albedo at the colleg, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f the cnt construct, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: to life in abu dhab, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hist culture tends t, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: untry in north centr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ll of the old author, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anarchism and anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ponsibility for prov, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ing in a manner cons, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ute hidden meaning t, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: syndicalists like r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: thoughts about raci, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: is impossible with c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s the first internat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: mile pataud and emil, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hists list of anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e eight five zero s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rchism and the envir, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e by doing so they c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: es and information f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: are and development, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: end up as bad as th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: two one kronstadt r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: places like germany, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: bu dhabi introduced, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ifference between th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: jor anarcho syndical, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: luddites and the wr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: autistic which is qu, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ated to explaining h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: or a post revolution, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: s to achieve these g, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: g in terms of class, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: they feel self consc, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: there are numerous r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s although interpret, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ng communication dev, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rl industry in the f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: cs some examples of, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: onse to the army reb, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: olonialism and zapat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: y in relation to ant, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: been accepted as a l, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: d the incentive to r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: one nine seven two, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: its and ensure that, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: alues found in north, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: people with autism s, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ears to increase by, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: l a anarchism small, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: o anti capitalist pr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ups in france and it, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: d anarchist pierre j, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ce the beliefs of pr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: researchers remain, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ncerns eco feminism, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: a number new of mov, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s and anxiety prepar, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: voting is explained, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: explosive behavior, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ks on a smaller scal, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: health sciences cent, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: icial diagnosis see, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: as accurately depict, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: workers solidarity d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ability to fully dec, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nated in the one nin, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rm on line communiti, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: e that if feminists, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f the classroom a te, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: nities they also occ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: odern abu dhabi trac, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: this is a brief summ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: an is a communist i, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: the us espoused uni, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: which sees the domin, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: erages between nine, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ell they feel self c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ature range the diff, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: at autism is a uniqu, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: king symptoms must h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nd high functioning, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: one nine seven thre, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: sive developmental d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eber and andrej grub, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ebsite created to br, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ectivised factories, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: of these early sympt, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: war see also anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t autistic people ar, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nstitute of mental h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: l social and languag, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: le of the two in rec, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s an anarchist and s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ans rule our lives y, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: with autism do what, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: i n d institute in c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ied some of these ar, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e label early infant, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: labour as private pr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: right wing libertari, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hildren with relativ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: g to the zapatista r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hs autism like sympt, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: related social movem, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: eportedly common in, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: orbed and the temper, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ir two zero s depend, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: y anxious or depress, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ck of individual sov, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: chance we re seeing, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: in the skills and b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ts and schools have, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: angle of incidence, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: proponents include w, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anarcho capitalist s, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: stic spectrum disord, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: y allowing them to w, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: to flow to the area, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ble it represents th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: disability or diseas, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: two eight one nine, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: r three days showed, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: els to children who, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ained to power its l, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: m seems to lack thes, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: epidemiologists arg, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: kers of the world an, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: en portrayed as dang, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: he study of autism a, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: d leader in the amer, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ot unwinding or calm, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ism falls into the p, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: gh a revolution is c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: practice many autist, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s germinal for the d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: created by the contr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tes arose from treat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: r during gestation d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ods or throughout th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: five eight million, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: iolence such as bomb, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: that civilization n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: three emirates palac, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: greater the tropics, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: statistical manual, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: els further these tw, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: clear etc it calls f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: learinghouse for inf, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ivil rights and cult, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anarchism in spain, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: characterised as sp, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ne nine of em radiat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: o several groups ess, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: tistics autistics wh, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: later became known, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ls away from any soc, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: neral and the very n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: from the everyday n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: garding the developm, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ed during the late w, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: o transform abu dhab, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ose who do speak oft, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: diagnostic and stat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: l student because th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: in both opposed comm, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: intervention and reg, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: or asperger s syndr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: art of the united ar, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f autism as a commun, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: events but there ar, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: one social interact, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: unusual repetitive m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: hist organizations m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: opmental disorder th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e label early infant, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: mmunicate have expla, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: are nearly dysfuncti, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ght zero if a margin, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ected human activiti, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: d take of non autist, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: zero expatriate pop, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nnected contexts dav, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s may be delayed dev, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: individuals can hav, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ds on the size of th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: that leaves them un, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: y an attempt to comp, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: on of documentaries, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: dualistically inclin, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: illiam godwin anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: l anarchist communit, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: olutionary movement, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: the theory and pract, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: anarcho capitalism, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ed disorders and for, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t anarchist periodic, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: alistically utopian, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: zero with about an, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: perty however other, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: e five pervasive dev, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s new discoveries ab, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: truda group of russ, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: iving off the coast, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ed mainly by camel h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: over the land surfac, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ice directory of uk, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: iatric criteria and, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ith the better off f, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ualified it refers t, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ide of the leftist m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: o zero square miles, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: evere cases as accur, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ite in associations, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rnia one seven octob, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ts movement this art, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: y this has brought r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: es a way of life res, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: isaac puente s one n, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: d in one nine six on, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: sented this way beca, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: as also postmarked b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: the national instit, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: essays peter kropotk, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ies may contribute t, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: re is no higher auth, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: on the other hand h, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ic and statistical m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: culators and fast pr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: utionary industrial, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: nst in one eight sev, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rchist movement part, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: and october revoluti, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: alth and human devel, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: f the united arab em, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ket anarchism max st, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: he us for example th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: proportion of these, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: r schools some such, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: chists to express th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: and author hans alfr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ction of dates and v, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: determine a diagnos, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: popular culture is r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: sm while many anarch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: med by the rise of f, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ts came close to ins, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: gmt four hours trivi, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: idst much internal c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: wo electromagnetic r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ward walker s study, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: s in social interact, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: l manual of mental d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: loud feedbacks furth, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ifesto known as the, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: form of autism in th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: mperatures see contr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: n dunlap lise fox er, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: rom genetically medi, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: te is incompatible w, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: d asperger s syndrom, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: conf d ration g n r, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: her a harmonious ant, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: chools of thought ar, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: y europe are sometim, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ntly in relation to, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: strict pacifists th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: sm was applied to th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ware once given appr, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ious struggles and m, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: she believes that c, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: sequence of a singl, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: verse with other aut, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ation no nih zero fo, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: in place of what ar, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: ing taught some stud, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: propaganda by the d, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ast most autistic ch, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: gues that the treatm, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: and continued to be, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: sue causes anti war, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: l property is underm, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: t is the most author, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: of the united arab, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ssroom a teacher s a, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: n voluntary associat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: budhabi com abu dhab, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: amost however there, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: century this has bro, Predicted: 0, Actual: 1, Result: Incorrect\n",
            "Example: dents for new situat, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: verbal outbursts th, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: narchism several ind, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ointing out objects, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: ability or disease w, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: raits autism childho, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: nine six zero postag, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: introduction of thes, Predicted: 1, Actual: 1, Result: Correct\n",
            "Example: let alone that the b, Predicted: 1, Actual: 1, Result: Correct\n",
            "Accuracy on Development Set: 0.7690\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'class LanguageModel(object):\\n    def __init__(self, model_emb, model_dec, vocab_index):\\n        self.model_emb = model_emb\\n        self.model_dec = model_dec\\n        self.vocab_index = vocab_index\\n        self.hidden_size = model_dec.hidden_size\\n        self.output_layer = nn.Linear(self.hidden_size, len(vocab_index))  # Linear layer to map to vocab size\\n\\n\\nclass RNNLanguageModel(nn.Module):\\n    def __init__(self, embedding_layer, rnn_layer, vocab_size):\\n        super(RNNLanguageModel, self).__init__()\\n        self.model_emb = embedding_layer  # Embedding layer\\n        self.model_dec = rnn_layer  # GRU/LSTM or any RNN layer\\n        self.fc = nn.Linear(rnn_layer.hidden_size, vocab_size)  # Linear layer to project to vocab size\\n        self.dropout = nn.Dropout(0.5)  # Dropout to prevent overfitting\\n\\n    def forward(self, inputs):\\n        embeddings = self.model_emb(inputs)  # Convert inputs to embeddings\\n        embeddings = self.dropout(embeddings)\\n        rnn_output, hidden = self.model_dec(embeddings)  # Get RNN outputs\\n        rnn_output = self.dropout(rnn_output)\\n        logits = self.fc(rnn_output)  # Project RNN outputs to vocab size\\n        return logits, hidden\\n\\n\\ndef train_lm(args, train_text, dev_text, vocab_index):\\n    # Define hyperparameters\\n    embedding_dim = 128  # Increased embedding size\\n    hidden_size = 128  # Increased hidden size\\n    num_layers = 3  # More layers for more complex representation\\n    learning_rate = 0.0005  # Adjust learning rate\\n    num_epochs = 20  # Increase number of epochs\\n    batch_size = 32\\n    vocab_size = len(vocab_index)\\n\\n    # Instantiate the RNN model\\n    rnn_model = RNNLanguageModel(\\n        nn.Embedding(vocab_size, embedding_dim),\\n        nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=0.3),\\n        vocab_size  # Pass vocab_size to the linear layer\\n    )\\n\\n    # Loss and optimizer\\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\\n    optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=learning_rate)\\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\'min\\', patience=3, factor=0.5)\\n\\n    # Early stopping parameters\\n    best_dev_accuracy = 0\\n    early_stop_patience = 5\\n    patience_counter = 0\\n\\n    # Training loop\\n    for epoch in range(num_epochs):\\n        rnn_model.train()  # Set model to training mode\\n        total_loss = 0\\n        correct_predictions = 0\\n        total_predictions = 0\\n\\n        for i in range(0, len(train_text) - batch_size, batch_size):\\n            inputs = torch.tensor([[vocab_index[char] for char in seq] for seq in train_text[i:i + batch_size]])\\n            targets = torch.tensor([[vocab_index[char] for char in seq[1:]] + [vocab_index[train_text[i][-1]]] for seq in train_text[i:i + batch_size]])\\n\\n            # Forward pass\\n            optimizer.zero_grad()\\n            output, _ = rnn_model(inputs)\\n\\n            # Reshape output and targets for loss function\\n            batch_size, seq_len, vocab_output_size = output.shape\\n            output = output.view(batch_size * seq_len, vocab_output_size)  # Reshape to (batch_size * seq_len, vocab_size)\\n            targets = targets.view(-1)  # Flatten targets\\n\\n            # Compute loss\\n            loss = criterion(output, targets)\\n            total_loss += loss.item()\\n\\n            # Backpropagation\\n            loss.backward()\\n            torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), max_norm=1.0)  # Clip gradients\\n            optimizer.step()\\n\\n            # Accuracy calculation\\n            _, predicted = torch.max(output, 1)\\n            correct_predictions += (predicted == targets).sum().item()\\n            total_predictions += targets.size(0)\\n\\n        # Validate on the dev set\\n        rnn_model.eval()  # Set model to evaluation mode\\n        dev_correct = 0\\n        dev_total = 0\\n\\n        with torch.no_grad():\\n            for i in range(0, len(dev_text) - batch_size, batch_size):\\n                inputs = torch.tensor([[vocab_index[char] for char in seq] for seq in dev_text[i:i + batch_size]])\\n                targets = torch.tensor([[vocab_index[char] for char in seq[1:]] + [vocab_index[dev_text[i][-1]]] for seq in dev_text[i:i + batch_size]])\\n\\n                output, _ = rnn_model(inputs)\\n                output = output.view(batch_size * seq_len, vocab_output_size)\\n                targets = targets.view(-1)\\n\\n                _, predicted = torch.max(output, 1)\\n                dev_correct += (predicted == targets).sum().item()\\n                dev_total += targets.size(0)\\n\\n        dev_accuracy = (dev_correct / dev_total) * 100\\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Training Accuracy: {(correct_predictions / total_predictions) * 100:.2f}%, Dev Accuracy: {dev_accuracy:.2f}%\")\\n\\n        # Learning rate scheduler step\\n        scheduler.step(total_loss)\\n\\n        # Early stopping\\n        if dev_accuracy > best_dev_accuracy:\\n            best_dev_accuracy = dev_accuracy\\n            patience_counter = 0  # Reset patience if accuracy improves\\n        else:\\n            patience_counter += 1  # Increment if no improvement\\n\\n        if patience_counter >= early_stop_patience:\\n            print(\"Early stopping due to no improvement.\")\\n            break\\n\\n    return rnn_model\\n\\n\\ndef load_examples(file_path):\\n    with open(file_path, \\'r\\') as file:\\n        return [line.strip() for line in file.readlines()]\\n\\n\\nif __name__ == \"__main__\":\\n    # Load training and development examples\\n    train_cons_exs = load_examples(\\'train-consonant-examples.txt\\')\\n    train_vowel_exs = load_examples(\\'train-vowel-examples.txt\\')\\n    dev_cons_exs = load_examples(\\'dev-consonant-examples.txt\\')\\n    dev_vowel_exs = load_examples(\\'dev-vowel-examples.txt\\')\\n\\n    # Combine all the training and development data\\n    train_text = \\'\\'.join(train_cons_exs + train_vowel_exs)\\n    dev_text = \\'\\'.join(dev_cons_exs + dev_vowel_exs)\\n\\n    # Create vocabulary index directly from the text\\n    vocab_set = set(train_text + dev_text)\\n    vocab_index = {char: idx for idx, char in enumerate(sorted(vocab_set))}\\n\\n    # Train the language model\\n    model = train_lm(None, train_text, dev_text, vocab_index)\\n\\n    print(\"Training complete. RNN language model is ready.\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "def load_examples(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]\n",
        "\n",
        "def create_vocab_index(examples):\n",
        "    vocab_set = set()\n",
        "    for ex in examples:\n",
        "        vocab_set.update(ex)  # Add all characters from the examples\n",
        "    vocab_list = sorted(vocab_set)  # Sort to maintain consistent indexing\n",
        "    return {char: idx for idx, char in enumerate(vocab_list)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training and development examples\n",
        "    train_cons_exs = load_examples('train-consonant-examples.txt')\n",
        "    train_vowel_exs = load_examples('train-vowel-examples.txt')\n",
        "    dev_cons_exs = load_examples('dev-consonant-examples.txt')\n",
        "    dev_vowel_exs = load_examples('dev-vowel-examples.txt')\n",
        "\n",
        "    # Create vocabulary index\n",
        "    vocab_index = create_vocab_index(train_cons_exs + train_vowel_exs + dev_cons_exs + dev_vowel_exs)\n",
        "\n",
        "    # Train the classifier\n",
        "    model = train_rnn_classifier(None, train_cons_exs, train_vowel_exs, dev_cons_exs, dev_vowel_exs, vocab_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODELS FOR PART 2"
      ],
      "metadata": {
        "id": "bPT4FPMfysxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''class LanguageModel(object):\n",
        "    def __init__(self, model_emb, model_dec, vocab_index):\n",
        "        self.model_emb = model_emb\n",
        "        self.model_dec = model_dec\n",
        "        self.vocab_index = vocab_index\n",
        "        self.hidden_size = model_dec.hidden_size\n",
        "        self.output_layer = nn.Linear(self.hidden_size, len(vocab_index))  # Linear layer to map to vocab size\n",
        "\n",
        "\n",
        "class RNNLanguageModel(nn.Module):\n",
        "    def __init__(self, embedding_layer, rnn_layer, vocab_size):\n",
        "        super(RNNLanguageModel, self).__init__()\n",
        "        self.model_emb = embedding_layer  # Embedding layer\n",
        "        self.model_dec = rnn_layer  # GRU/LSTM or any RNN layer\n",
        "        self.fc = nn.Linear(rnn_layer.hidden_size, vocab_size)  # Linear layer to project to vocab size\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout to prevent overfitting\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.model_emb(inputs)  # Convert inputs to embeddings\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        rnn_output, hidden = self.model_dec(embeddings)  # Get RNN outputs\n",
        "        rnn_output = self.dropout(rnn_output)\n",
        "        logits = self.fc(rnn_output)  # Project RNN outputs to vocab size\n",
        "        return logits, hidden\n",
        "\n",
        "\n",
        "def train_lm(args, train_text, dev_text, vocab_index):\n",
        "    # Define hyperparameters\n",
        "    embedding_dim = 128  # Increased embedding size\n",
        "    hidden_size = 128  # Increased hidden size\n",
        "    num_layers = 3  # More layers for more complex representation\n",
        "    learning_rate = 0.0005  # Adjust learning rate\n",
        "    num_epochs = 20  # Increase number of epochs\n",
        "    batch_size = 32\n",
        "    vocab_size = len(vocab_index)\n",
        "\n",
        "    # Instantiate the RNN model\n",
        "    rnn_model = RNNLanguageModel(\n",
        "        nn.Embedding(vocab_size, embedding_dim),\n",
        "        nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True, dropout=0.3),\n",
        "        vocab_size  # Pass vocab_size to the linear layer\n",
        "    )\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    best_dev_accuracy = 0\n",
        "    early_stop_patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        rnn_model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for i in range(0, len(train_text) - batch_size, batch_size):\n",
        "            inputs = torch.tensor([[vocab_index[char] for char in seq] for seq in train_text[i:i + batch_size]])\n",
        "            targets = torch.tensor([[vocab_index[char] for char in seq[1:]] + [vocab_index[train_text[i][-1]]] for seq in train_text[i:i + batch_size]])\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output, _ = rnn_model(inputs)\n",
        "\n",
        "            # Reshape output and targets for loss function\n",
        "            batch_size, seq_len, vocab_output_size = output.shape\n",
        "            output = output.view(batch_size * seq_len, vocab_output_size)  # Reshape to (batch_size * seq_len, vocab_size)\n",
        "            targets = targets.view(-1)  # Flatten targets\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(output, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), max_norm=1.0)  # Clip gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy calculation\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            correct_predictions += (predicted == targets).sum().item()\n",
        "            total_predictions += targets.size(0)\n",
        "\n",
        "        # Validate on the dev set\n",
        "        rnn_model.eval()  # Set model to evaluation mode\n",
        "        dev_correct = 0\n",
        "        dev_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(dev_text) - batch_size, batch_size):\n",
        "                inputs = torch.tensor([[vocab_index[char] for char in seq] for seq in dev_text[i:i + batch_size]])\n",
        "                targets = torch.tensor([[vocab_index[char] for char in seq[1:]] + [vocab_index[dev_text[i][-1]]] for seq in dev_text[i:i + batch_size]])\n",
        "\n",
        "                output, _ = rnn_model(inputs)\n",
        "                output = output.view(batch_size * seq_len, vocab_output_size)\n",
        "                targets = targets.view(-1)\n",
        "\n",
        "                _, predicted = torch.max(output, 1)\n",
        "                dev_correct += (predicted == targets).sum().item()\n",
        "                dev_total += targets.size(0)\n",
        "\n",
        "        dev_accuracy = (dev_correct / dev_total) * 100\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Training Accuracy: {(correct_predictions / total_predictions) * 100:.2f}%, Dev Accuracy: {dev_accuracy:.2f}%\")\n",
        "\n",
        "        # Learning rate scheduler step\n",
        "        scheduler.step(total_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if dev_accuracy > best_dev_accuracy:\n",
        "            best_dev_accuracy = dev_accuracy\n",
        "            patience_counter = 0  # Reset patience if accuracy improves\n",
        "        else:\n",
        "            patience_counter += 1  # Increment if no improvement\n",
        "\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping due to no improvement.\")\n",
        "            break\n",
        "\n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "def load_examples(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load training and development examples\n",
        "    train_cons_exs = load_examples('train-consonant-examples.txt')\n",
        "    train_vowel_exs = load_examples('train-vowel-examples.txt')\n",
        "    dev_cons_exs = load_examples('dev-consonant-examples.txt')\n",
        "    dev_vowel_exs = load_examples('dev-vowel-examples.txt')\n",
        "\n",
        "    # Combine all the training and development data\n",
        "    train_text = ''.join(train_cons_exs + train_vowel_exs)\n",
        "    dev_text = ''.join(dev_cons_exs + dev_vowel_exs)\n",
        "\n",
        "    # Create vocabulary index directly from the text\n",
        "    vocab_set = set(train_text + dev_text)\n",
        "    vocab_index = {char: idx for idx, char in enumerate(sorted(vocab_set))}\n",
        "\n",
        "    # Train the language model\n",
        "    model = train_lm(None, train_text, dev_text, vocab_index)\n",
        "\n",
        "    print(\"Training complete. RNN language model is ready.\")'''\n"
      ],
      "metadata": {
        "id": "8FeeRe6nygg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###lm.py code"
      ],
      "metadata": {
        "id": "RzLQwsQuRlpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lm.py\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "from models import *\n",
        "from utils import *\n",
        "\n",
        "####################################################\n",
        "# DO NOT MODIFY THIS FILE IN YOUR FINAL SUBMISSION #\n",
        "####################################################\n",
        "\n",
        "\n",
        "def _parse_args():\n",
        "    \"\"\"\n",
        "    Command-line arguments to the system. --model switches between the main modes you'll need to use.\n",
        "    The other arguments are provided for convenience.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description='lm.py')\n",
        "    parser.add_argument('--model', type=str, default='UNIFORM', help='model to run (UNIFORM or RNN)')\n",
        "    parser.add_argument('--train_path', type=str, default='text8-100k.txt', help='path to train set')\n",
        "    parser.add_argument('--dev_path', type=str, default='text8-dev.txt', help='path to dev set')\n",
        "\n",
        "    # Add this line to ignore unknown arguments from Jupyter/Colab\n",
        "    args, unknown = parser.parse_known_args()  # This will allow extra arguments (like -f) to be ignored\n",
        "    return args\n",
        "\n",
        "\n",
        "\n",
        "def read_text(file):\n",
        "    \"\"\"\n",
        "    :param file:\n",
        "    :return: The text in the given file as a single string\n",
        "    \"\"\"\n",
        "    all_text = \"\"\n",
        "    for line in open(file):\n",
        "        all_text += line.strip()\n",
        "    print(\"%i chars read in\" % len(all_text))\n",
        "    return all_text\n",
        "\n",
        "\n",
        "def print_evaluation(text, lm):\n",
        "    \"\"\"\n",
        "    Runs the language model on the given text and prints three metrics: log probability of the text under this model\n",
        "    (treating the text as one log sequence), average log probability (the previous value divided by sequence length),\n",
        "    and perplexity (averaged \"branching favor\" of the model)\n",
        "    :param text: the text to evaluate\n",
        "    :param lm: model to evaluate\n",
        "    \"\"\"\n",
        "    log_prob = lm.get_log_prob_sequence(text, \" \")\n",
        "    print(\"Log prob of text %f\" % log_prob)\n",
        "    print(\"Avg log prob: %f\" % (log_prob/len(text)))\n",
        "    perplexity = np.exp(-log_prob/len(text))\n",
        "    print(\"Perplexity: %f\" % perplexity)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    args = _parse_args()\n",
        "    print(args)\n",
        "\n",
        "    train_text = read_text(args.train_path)\n",
        "    dev_text = read_text(args.dev_path)\n",
        "\n",
        "    # Vocabs is lowercase letters a to z and space\n",
        "    vocab = [chr(ord('a') + i) for i in range(0, 26)] + [' ']\n",
        "    vocab_index = Indexer()\n",
        "    for char in vocab:\n",
        "        vocab_index.add_and_get_index(char)\n",
        "    print(repr(vocab_index))\n",
        "\n",
        "    print(\"First 100 characters of train:\")\n",
        "    print(train_text[0:100])\n",
        "    system_to_run = args.model\n",
        "    # Train our model\n",
        "    if system_to_run == \"RNN\":\n",
        "        model = train_lm(args, train_text, dev_text, vocab_index)\n",
        "    elif system_to_run == \"UNIFORM\":\n",
        "        model = UniformLanguageModel(len(vocab))\n",
        "    else:\n",
        "        raise Exception(\"Pass in either UNIFORM or LSTM to run the appropriate system\")\n",
        "\n",
        "    print_evaluation(dev_text, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuqhakjMPxxZ",
        "outputId": "51e64d81-ccea-46aa-c374-5a5fce0d3a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(model='UNIFORM', train_path='text8-100k.txt', dev_path='text8-dev.txt')\n",
            "99999 chars read in\n",
            "499 chars read in\n",
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
            "First 100 characters of train:\n",
            "anarchism originated as a term of abuse first used against early working class radicals including th\n",
            "Log prob of text -1644.622596\n",
            "Avg log prob: -3.295837\n",
            "Perplexity: 27.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# RNN Language Model Definition\n",
        "class RNNLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(RNNLanguageModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)  # You can use LSTM here as well\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)  # Output layer to predict next character\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        x = self.embedding(x)  # Convert character indices to embeddings\n",
        "        out, hidden_state = self.rnn(x, hidden_state)  # Pass through RNN\n",
        "        out = self.fc(out)  # Project RNN outputs to vocab size\n",
        "        return out, hidden_state\n",
        "\n",
        "# Function to chunk data for training/evaluation\n",
        "def chunk_data(text, chunk_size, vocab_index):\n",
        "    input_data = []\n",
        "    target_data = []\n",
        "    for i in range(0, len(text) - chunk_size, chunk_size):\n",
        "        input_chunk = text[i:i + chunk_size]\n",
        "        target_chunk = text[i + 1:i + chunk_size + 1]\n",
        "        input_data.append([vocab_index.index_of(c) for c in input_chunk])\n",
        "        target_data.append([vocab_index.index_of(c) for c in target_chunk])\n",
        "    return torch.tensor(input_data), torch.tensor(target_data)\n",
        "\n",
        "# Training loop\n",
        "def train_lm(args, train_text, dev_text, vocab_index):\n",
        "    # Hyperparameters\n",
        "    embed_size = 128\n",
        "    hidden_size = 256\n",
        "    chunk_size = 100  # You can experiment with this\n",
        "\n",
        "    # Model, loss, optimizer\n",
        "    vocab_size = len(vocab_index)\n",
        "    model = RNNLanguageModel(vocab_size, embed_size, hidden_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Process data into chunks\n",
        "    train_input, train_target = chunk_data(train_text, chunk_size, vocab_index)\n",
        "\n",
        "    # Training loop\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        hidden_state = None  # Start with None or init hidden state with zeros\n",
        "\n",
        "        for batch_idx in range(len(train_input)):\n",
        "            inputs = train_input[batch_idx].unsqueeze(0)  # Add batch dimension\n",
        "            targets = train_target[batch_idx].unsqueeze(0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden_state = model(inputs, hidden_state)  # Forward pass\n",
        "\n",
        "            # Detach hidden state to prevent backpropagation through time\n",
        "            if hidden_state is not None:\n",
        "                hidden_state = hidden_state.detach()\n",
        "\n",
        "            loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}')\n",
        "\n",
        "        # Evaluate on dev set after each epoch\n",
        "        print(\"Evaluating on dev set...\")\n",
        "        evaluate(dev_text, model, vocab_index, chunk_size)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluation function to calculate log prob, perplexity, and accuracy\n",
        "def evaluate(dev_text, model, vocab_index, chunk_size):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    dev_input, dev_target = chunk_data(dev_text, chunk_size, vocab_index)\n",
        "\n",
        "    total_log_prob = 0\n",
        "    total_perplexity = 0\n",
        "    total_count = 0\n",
        "    total_correct = 0  # To count correct predictions\n",
        "    criterion = nn.CrossEntropyLoss(reduction='sum')  # Summing the losses\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden_state = None\n",
        "        for batch_idx in range(len(dev_input)):\n",
        "            inputs = dev_input[batch_idx].unsqueeze(0)\n",
        "            targets = dev_target[batch_idx].unsqueeze(0)\n",
        "            output, hidden_state = model(inputs, hidden_state)\n",
        "\n",
        "            log_prob = -criterion(output.view(-1, len(vocab_index)), targets.view(-1))\n",
        "            perplexity = torch.exp(log_prob / targets.numel())  # Normalize by number of targets\n",
        "\n",
        "            total_log_prob += log_prob.item()\n",
        "            total_perplexity += perplexity.item()\n",
        "            total_count += targets.numel()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            predictions = output.argmax(dim=-1)  # Get the index of the max logit (predicted character)\n",
        "            correct = (predictions == targets).sum().item()\n",
        "            total_correct += correct\n",
        "\n",
        "    avg_log_prob = total_log_prob / total_count\n",
        "    avg_perplexity = total_perplexity / len(dev_input)\n",
        "    accuracy = total_correct / total_count * 100  # Convert to percentage\n",
        "\n",
        "    # Structured output\n",
        "    print(f'Log prob of text: {total_log_prob:.6f}')\n",
        "    print(f'Avg log prob: {avg_log_prob:.6f}')\n",
        "    print(f'Perplexity: {avg_perplexity:.6f}')\n",
        "    print(f'Accuracy: {accuracy:.2f}%')  # Print accuracy\n",
        "\n",
        "# Main part to load data and run the model\n",
        "def main():\n",
        "    # Placeholder paths\n",
        "    train_path = 'text8-100k.txt'\n",
        "    dev_path = 'text8-dev.txt'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    with open(train_path, 'r') as f:\n",
        "        train_text = f.read().lower()\n",
        "    with open(dev_path, 'r') as f:\n",
        "        dev_text = f.read().lower()\n",
        "\n",
        "    # Sample vocab_index creation (You should have a proper class or function for this)\n",
        "    vocab = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
        "\n",
        "    class VocabIndex:\n",
        "        def __init__(self, vocab):\n",
        "            self.vocab = vocab\n",
        "\n",
        "        def index_of(self, char):\n",
        "            return self.vocab.index(char)\n",
        "\n",
        "        def char_of(self, index):\n",
        "            return self.vocab[index]\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.vocab)  # This allows `len(vocab_index)` to work\n",
        "\n",
        "    vocab_index = VocabIndex(vocab)\n",
        "\n",
        "    # Run the training function\n",
        "    args = {'model': 'RNN', 'train_path': train_path, 'dev_path': dev_path}\n",
        "    model = train_lm(args, train_text, dev_text, vocab_index)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "8TfphdYkRsIE",
        "outputId": "4e128fbf-fbd4-473b-e5cc-ae39b8af1f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Batch 0, Loss: 3.2877674102783203\n",
            "Epoch 0, Batch 100, Loss: 2.031649112701416\n",
            "Epoch 0, Batch 200, Loss: 1.8407940864562988\n",
            "Epoch 0, Batch 300, Loss: 2.266396999359131\n",
            "Epoch 0, Batch 400, Loss: 1.6026535034179688\n",
            "Epoch 0, Batch 500, Loss: 2.265138864517212\n",
            "Epoch 0, Batch 600, Loss: 1.7970640659332275\n",
            "Epoch 0, Batch 700, Loss: 2.388536214828491\n",
            "Epoch 0, Batch 800, Loss: 2.1008963584899902\n",
            "Epoch 0, Batch 900, Loss: 2.5031557083129883\n",
            "Evaluating on dev set...\n",
            "Log prob of text: -970.840714\n",
            "Avg log prob: -2.427102\n",
            "Perplexity: 0.091863\n",
            "Accuracy: 30.00%\n",
            "Epoch 1, Batch 0, Loss: 2.597507953643799\n",
            "Epoch 1, Batch 100, Loss: 2.3390021324157715\n",
            "Epoch 1, Batch 200, Loss: 1.8133666515350342\n",
            "Epoch 1, Batch 300, Loss: 2.378232479095459\n",
            "Epoch 1, Batch 400, Loss: 1.6543529033660889\n",
            "Epoch 1, Batch 500, Loss: 2.191693067550659\n",
            "Epoch 1, Batch 600, Loss: 2.011711597442627\n",
            "Epoch 1, Batch 700, Loss: 2.402981758117676\n",
            "Epoch 1, Batch 800, Loss: 2.2110376358032227\n",
            "Epoch 1, Batch 900, Loss: 2.299504280090332\n",
            "Evaluating on dev set...\n",
            "Log prob of text: -949.621262\n",
            "Avg log prob: -2.374053\n",
            "Perplexity: 0.095494\n",
            "Accuracy: 33.25%\n",
            "Epoch 2, Batch 0, Loss: 2.298144578933716\n",
            "Epoch 2, Batch 100, Loss: 2.22869610786438\n",
            "Epoch 2, Batch 200, Loss: 1.8106738328933716\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-18ce18381bab>\u001b[0m in \u001b[0;36m<cell line: 149>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-18ce18381bab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# Run the training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'RNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-18ce18381bab>\u001b[0m in \u001b[0;36mtrain_lm\u001b[0;34m(args, train_text, dev_text, vocab_index)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "\n",
        "#####################\n",
        "# MODELS FOR PART 2 #\n",
        "#####################\n",
        "\n",
        "class LanguageModel(object):\n",
        "    def get_log_prob_single(self, next_char, context):\n",
        "        \"\"\"\n",
        "        Scores one character following the given context. That is, returns\n",
        "        log P(next_char | context)\n",
        "        The log should be base e\n",
        "        :param next_char:\n",
        "        :param context: a single character to score\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        raise Exception(\"Only implemented in subclasses\")\n",
        "\n",
        "    def get_log_prob_sequence(self, next_chars, context):\n",
        "        \"\"\"\n",
        "        Scores a bunch of characters following context. That is, returns\n",
        "        log P(nc1, nc2, nc3, ... | context) = log P(nc1 | context) + log P(nc2 | context, nc1), ...\n",
        "        The log should be base e\n",
        "        :param next_chars:\n",
        "        :param context:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        raise Exception(\"Only implemented in subclasses\")\n",
        "\n",
        "\n",
        "class UniformLanguageModel(LanguageModel):\n",
        "    def __init__(self, voc_size):\n",
        "        self.voc_size = voc_size\n",
        "\n",
        "    def get_log_prob_single(self, next_char, context):\n",
        "        return np.log(1.0 / self.voc_size)\n",
        "\n",
        "    def get_log_prob_sequence(self, next_chars, context):\n",
        "        return np.log(1.0 / self.voc_size) * len(next_chars)\n",
        "\n",
        "\n",
        "class RNNLanguageModel(LanguageModel):\n",
        "    def __init__(self, model_emb, model_dec, vocab_index):\n",
        "        self.model_emb = model_emb\n",
        "        self.model_dec = model_dec\n",
        "        self.vocab_index = vocab_index\n",
        "\n",
        "    def get_log_prob_single(self, next_char, context):\n",
        "        # Convert next_char to the index in the vocab\n",
        "        next_char_idx = self.vocab_index.index(next_char)  # Change this line to use `index()`\n",
        "\n",
        "        # Convert context to a tensor of indices\n",
        "        context_idx = torch.tensor([self.vocab_index.index(c) for c in context], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        with torch.no_grad():\n",
        "            output, _ = self.model_emb(context_idx)\n",
        "            logits = self.model_dec(output)\n",
        "\n",
        "        # Log probability of the next character\n",
        "        log_prob = torch.log_softmax(logits[:, -1, :], dim=-1)\n",
        "        return log_prob[0, next_char_idx].item()\n",
        "\n",
        "    def get_log_prob_sequence(self, next_chars, context):\n",
        "        log_prob_sum = 0\n",
        "        for i in range(len(next_chars)):\n",
        "            log_prob_sum += self.get_log_prob_single(next_chars[i], context)\n",
        "            context += next_chars[i]\n",
        "        return log_prob_sum\n",
        "\n",
        "\n",
        "class RNNLanguageModelImpl(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(RNNLanguageModelImpl, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size, hidden_size, batch_first=True)  # You can use LSTM here as well\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)  # Output layer to predict next character\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        x = self.embedding(x)  # Convert character indices to embeddings\n",
        "        out, hidden_state = self.rnn(x, hidden_state)  # Pass through RNN\n",
        "        out = self.fc(out)  # Project RNN outputs to vocab size\n",
        "        return out, hidden_state\n",
        "\n",
        "\n",
        "def chunk_data(text, chunk_size, vocab_index):\n",
        "    input_data = []\n",
        "    target_data = []\n",
        "    for i in range(0, len(text) - chunk_size, chunk_size):\n",
        "        input_chunk = text[i:i + chunk_size]\n",
        "        target_chunk = text[i + 1:i + chunk_size + 1]\n",
        "        input_data.append([vocab_index[c] for c in input_chunk])  # Use vocab_index[c]\n",
        "        target_data.append([vocab_index[c] for c in target_chunk])  # Use vocab_index[c]\n",
        "    return torch.tensor(input_data), torch.tensor(target_data)\n",
        "\n",
        "\n",
        "def train_lm(args, train_text, dev_text, vocab_index):\n",
        "    # Hyperparameters\n",
        "    embed_size = 128\n",
        "    hidden_size = 256\n",
        "    chunk_size = 100  # You can experiment with this\n",
        "\n",
        "    # Model, loss, optimizer\n",
        "    vocab_size = len(vocab_index)\n",
        "\n",
        "    if args.model == 'RNN':\n",
        "        model_emb = RNNLanguageModelImpl(vocab_size, embed_size, hidden_size)\n",
        "        model_dec = nn.Linear(hidden_size, vocab_size)  # Define output layer separately\n",
        "        model = RNNLanguageModel(model_emb, model_dec, vocab_index)\n",
        "    elif args.model == 'UNIFORM':\n",
        "        model = UniformLanguageModel(vocab_size)\n",
        "        model_emb = None  # No embedding for Uniform model\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model type: \" + args.model)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model_emb.parameters(), lr=0.001) if args.model == 'RNN' else None\n",
        "\n",
        "    # Process data into chunks\n",
        "    train_input, train_target = chunk_data(train_text, chunk_size, vocab_index)\n",
        "\n",
        "    # Training loop\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        hidden_state = None  # Start with None or init hidden state with zeros\n",
        "\n",
        "        if args.model == 'RNN':\n",
        "            for batch_idx in range(len(train_input)):\n",
        "                inputs = train_input[batch_idx].unsqueeze(0)  # Add batch dimension\n",
        "                targets = train_target[batch_idx].unsqueeze(0)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output, hidden_state = model_emb(inputs, hidden_state)  # Forward pass\n",
        "\n",
        "                # Detach hidden state to prevent backpropagation through time\n",
        "                if hidden_state is not None:\n",
        "                    hidden_state = hidden_state.detach()\n",
        "\n",
        "                loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
        "                loss.backward()  # Backpropagation\n",
        "                optimizer.step()  # Update weights\n",
        "\n",
        "                if batch_idx % 100 == 0:\n",
        "                    print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}')\n",
        "\n",
        "        # Evaluate on dev set after each epoch\n",
        "        print(\"Evaluating on dev set...\")\n",
        "        evaluate(dev_text, model_emb, vocab_index, chunk_size)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(dev_text, model_emb, vocab_index, chunk_size, model_type='RNN'):\n",
        "    if model_type == 'RNN' and model_emb is not None:\n",
        "        model_emb.eval()  # Set model to evaluation mode if it's an RNN model\n",
        "\n",
        "    # Process dev text into input and target chunks\n",
        "    dev_input, dev_target = chunk_data(dev_text, chunk_size, vocab_index)\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Assuming we want to evaluate the model on the dev set\n",
        "    with torch.no_grad():  # No gradient calculations during evaluation\n",
        "        for batch_idx in range(len(dev_input)):\n",
        "            inputs = dev_input[batch_idx].unsqueeze(0)  # Add batch dimension\n",
        "            targets = dev_target[batch_idx].unsqueeze(0)\n",
        "\n",
        "            if model_type == 'RNN' and model_emb is not None:\n",
        "                output, _ = model_emb(inputs, None)  # Forward pass for RNN model\n",
        "            elif model_type == 'UNIFORM':\n",
        "                # For uniform model, predict using uniform distribution over vocabulary\n",
        "                # Assuming uniform model randomly picks a character from vocab\n",
        "                output = torch.full((inputs.size(0), inputs.size(1), len(vocab_index)), 1.0 / len(vocab_index)).to(inputs.device)\n",
        "\n",
        "            loss = nn.CrossEntropyLoss()(output.view(-1, len(vocab_index)), targets.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy (if needed)\n",
        "            _, predicted = output.max(2)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.numel()\n",
        "\n",
        "    avg_loss = total_loss / len(dev_input)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Evaluation loss: {avg_loss:.4f}\")\n",
        "    print(f\"Evaluation accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Argument parser\n",
        "    parser = argparse.ArgumentParser(description='Language Model Training and Evaluation')\n",
        "    parser.add_argument('--model', type=str, default='UNIFORM', help='Model to run (UNIFORM or RNN)')\n",
        "    parser.add_argument('--train_path', type=str, default='text8-100k.txt', help='Path to train set')\n",
        "    parser.add_argument('--dev_path', type=str, default='text8-dev.txt', help='Path to dev set')\n",
        "\n",
        "    # Use parse_known_args to ignore unknown arguments\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    with open(args.train_path, 'r') as f:\n",
        "        train_text = f.read()\n",
        "\n",
        "    with open(args.dev_path, 'r') as f:\n",
        "        dev_text = f.read()\n",
        "\n",
        "    # Build vocabulary\n",
        "    vocab = sorted(set(train_text))  # Update with your actual vocab\n",
        "    vocab_index = {char: idx for idx, char in enumerate(vocab)}\n",
        "\n",
        "    # Train model\n",
        "    model = train_lm(args, train_text, dev_text, vocab_index)\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "QK4TWqKoZgdW",
        "outputId": "9f611856-24ed-4839-f61a-624a497b33a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on dev set...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'output' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-990286b7829e>\u001b[0m in \u001b[0;36m<cell line: 224>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-990286b7829e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-990286b7829e>\u001b[0m in \u001b[0;36mtrain_lm\u001b[0;34m(args, train_text, dev_text, vocab_index)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Evaluate on dev set after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating on dev set...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-990286b7829e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dev_text, model_emb, vocab_index, chunk_size, model_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'output' referenced before assignment"
          ]
        }
      ]
    }
  ]
}